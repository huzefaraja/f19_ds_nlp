{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK Named Entity Extraction\n",
    "\n",
    "This basic demonstration shows how to use the NLTK library to extract named entities. It is somewhat more complicated than Spacy as it requires you to do the preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell we setup the tokenization and part of speech tagging provided by nltk. \n",
    "# From this we will be able to assigned named entity tags to the words and POS tuples\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "ex = \"\"\"Samsung ships 73 percent more phones, makes much less money. \n",
    "The issue is not just a deceptive portrayal of percentages of growth. \n",
    "Samsung's calendar Q2 mobile revenues from its IM segment were reported to be 22.67 Trillion KRW ($20 billion). \n",
    "Apple's net sales for the same quarter were more than double that: $53.265 billion. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are constructing a syntactic parse pattern that we will be able to extract chunks from the parsed sentences\n",
    "# Notice: It will attempt to identify noun phrases consisting of determiners adjuectives and nouns.\n",
    "\n",
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are examining the POS tags and syntactic parses and applying the CONLL tags to them.\n",
    "# basically these are indicating whether different words could constitute the beginning and \n",
    "# end of a chunk candidate.\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are running named entity extraction over the sentence.\n",
    "# this will tokenize, then part of speech tage, and finally identify Named entities\n",
    "# Notice, words like Samsung have an extra tag prepended. \n",
    "# in this case Samsung is identified as a geo-political entity, a person, etc.\n",
    "# not right, but it is at least recognized as something special.\n",
    "\n",
    "ne_tree =  nltk.ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Spacy - Now we will try a more sophisticated named entity extraction library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the models that you can install with Spacy contain named entity capabilities\n",
    "# although you should check if you are using languages other than English\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can apply Spacy to a document and then look at the ents property on the document object\n",
    "# this will give us a generator of entities that we can scan through.\n",
    "# Notice anything off with the returned entities?\n",
    "doc = nlp(ex)\n",
    "pprint([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use displacy to display a markedup version of the text with the entity tags applied.\n",
    "displacy.render(nlp(ex), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
