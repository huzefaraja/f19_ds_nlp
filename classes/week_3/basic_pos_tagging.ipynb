{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaging that we have a token stream and we are interesting in learning more about the structure of the sentece. For example, assume that we want to identify the various parts of speech in a sentece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "input = \"Specifically, we reviewed the AN/ASQâ€‘235 Airborne Mine Neutralization System (AMNS), Airborne Laser Mine Detection System (ALMDS), and Coastal Battlefield Reconnaissance and Analysis (COBRA) Block I systems.\"\n",
    "tokens = treebank_tokenizer.tokenize(input)\n",
    "print(tokens)\n",
    "\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this useful? Can we do anything with the actual tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_token in pos_tags:\n",
    "    print(pos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos_token in pos_tags:\n",
    "    print(pos_token[0] + \" -- \" + pos_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [pos_token[0] for pos_token in pos_tags if pos_token[1] == \"NNP\"]\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Attempting the same with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_stream = nlp(input)\n",
    "for i in token_stream:\n",
    "    print(i)\n",
    "    # the crucial difference is that Spacy marks up the whole document and then provides properties on each token.\n",
    "    # One of the Token properties you can look at is the part of speech\n",
    "    print(i.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
